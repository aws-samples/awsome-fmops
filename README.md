# Reference Architecture: Machine Learning Inference with KServe and Karpenter on Amazon EKS
## Overview
KServe offers a standard Kubernetes-based Model Inference Platform for scalable use-cases. Complementing it, Karpenter provides swift, simplified compute provisioning, optimally leveraging cloud resources. This synergy offers a unique opportunity to exploit Spot instances, enhancing cost efficiency. This reference architecture illustrates the mechanics of these technologies and demonstrate their combined power in enabling efficient serverless ML deployments.
This repository is built on top of [Karpenter Blueprints](https://github.com/aws-samples/karpenter-blueprints/tree/main). Please refer to the repository for the infrastructure set up.


## License

This library is licensed under the MIT-0 License. See the LICENSE file.

